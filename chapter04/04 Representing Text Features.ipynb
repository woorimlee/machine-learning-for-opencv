{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 텍트스 특징 표현하기\n",
    "+ Categorical variables를 표현할 때와 마찬가지로 scikit-learn에서 '텍스트 특징'을 쉽게 인코딩 할 수 있는 방법을 제공한다. \n",
    "+ 개별 단어 또는 문구를 숫자 값으로 인코딩해서 편하게 사용할 수 있다.\n",
    "+ 다음의 데이터 세트를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\n",
    "    'feature engineering',\n",
    "    'feature selection',\n",
    "    'feature extraction'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 이런 데이터를 인코딩하는 가장 간단한 방법 중 하나는 __word count(단어의 개수)__이다. 각 문구에서 단어 내의 각 단어 개수를 계산한다. \n",
    "  + CountVectorizer를 사용해 작업한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "X\n",
    "\n",
    "# 기본적으로 행렬 X를 희소 행렬(sparse matrix)로 저장한다. \n",
    "# 수작업으로 검사하고 싶으면 정규 배열로 다음과 같이 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 이 숫자들의 의미를 이해하려면 특징 이름을 살펴봐야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineering', 'extraction', 'feature', 'selection']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 이제 정수 X를 확인해보면, X의 맨 위 행에 표시된 문구에는 'engineering'이라는 단어가 한 개 있고, 'feature'라는 단어가 한 개 있다. 반면에, 'extraction' 또는 'selection'이라는 단어는 없다. (원래의 단어는 feature engineering)\n",
    "####   \n",
    "+ 이 접근법의 문제점은 매우 자주 나타나는 단어에 많은 가중치가 적용될 수 있다는 것이다.\n",
    "+ 이를 해결하기 위한 하나의 접근법은 __tf-idf(term frequency-inverse document frequency. 용어 빈도-역 문서 빈도)__이다. \n",
    "  + tf-idf는 기본적으로 단어 수를 전체 데이터 세트에 얼마나 자주 나타낼지 측정하는 방법을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.861037  ,  0.        ,  0.50854232,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.50854232,  0.861037  ],\n",
       "       [ 0.        ,  0.861037  ,  0.50854232,  0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 결과에서 확인할 수 있듯이 숫자가 이전보다 작아졌고, 자주 나타나는 단어 'feature'가 가장 작은 값을 갖는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineering', 'extraction', 'feature', 'selection']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 텍스트 특징을 나타내는 방법에 대한 내용은 7장의 베이지안 학습을 이용한 스팸 필터 구현에서 중요하게 사용된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
